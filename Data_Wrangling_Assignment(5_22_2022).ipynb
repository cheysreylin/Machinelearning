{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Wrangling_Assignment(5/22/2022).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDurfWQkYAYx5HLDOxMtRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheysreylin/Machinelearning/blob/main/Data_Wrangling_Assignment(5_22_2022).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TskP30Wn-Pz",
        "outputId": "1ad9c43c-4d66-4504-c45e-7bc6b3b5e380"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([284, 282, 279, 286, 244, 245, 289, 299, 351, 281, 273, 285, 255,\n",
              "       261, 288, 270, 274, 287, 276, 294, 280, 266, 292, 278, 268, 275,\n",
              "       283, 267, 293, 248, 272, 291, 258, 257, 232, 246, 277, 296, 305,\n",
              "       271, 302, 254, 303, 264, 243, 225, 269, 265, 262, 300, 318, 290,\n",
              "       301, 295, 306, 239, 320, 260, 234, 233, 249, 329, 328, 148, 256,\n",
              "       308, 319, 307, 315, 313, 304, 298, 297, 251, 263, 235, 323, 223,\n",
              "       252, 241, 247, 240, 250, 309, 316, 237, 259, 229, 242, 330, 253,\n",
              "       238, 228, 224, 181, 314, 204, 324, 312, 236, 311, 353, 338, 321])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import sklearn # machine learning\n",
        "import numpy as np # computation\n",
        "import pandas as pd # data management\n",
        "# 1. load the dataset\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/data-8/stat28/master/Labs/Lab1/baby.csv\")\n",
        "dataset.head(10)\n",
        "\n",
        "# 2. Dimention \n",
        "dataset.shape\n",
        "\n",
        "# 3. check the variable ( is it numerical or categorical )\n",
        "# Check numerical data\n",
        "numerical_variable = dataset.columns[dataset.dtypes != \"object\"]\n",
        "dataset[numerical_variable]\n",
        "\n",
        "# Check categorical data\n",
        "categorical_variable = dataset.columns[dataset.dtypes == \"object\"]\n",
        "dataset[categorical_variable]\n",
        "\n",
        "# 4.identify the missing value\n",
        "dataset.isnull()\n",
        "dataset[numerical_variable].isnull().head(10)\n",
        "dataset[categorical_variable].isnull().head(10)\n",
        "\n",
        "# 5. find out the percentage of missing value\n",
        "dataset.isnull().sum()/len(dataset)\n",
        "\n",
        "# 6. replace the missing value\n",
        "dataset.fillna(\"No missing value\")\n",
        "\n",
        "# 7. fillup the missing value with specific variable\n",
        "dataset['Maternal.Age'].replace(27,17)\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/data-8/stat28/master/Labs/Lab1/baby.csv\")\n",
        "dataset.head(10)\n",
        "# 8. create the row and add it with the original dataset\n",
        "row_insert = pd.Series([1175, 111, 289, 25, 66, 120, \"FALSE\"], index = [\"\",\"Birth.Weight\",\"Gestational.Days\",\"Maternal.Age\",\"Maternal.Height\",\"Maternal.Pregnancy.Weight\",\"Maternal.Smoker\"])\n",
        "dataset.append(row_insert, ignore_index = True)\n",
        "\n",
        "# 9. call the exact row from the dataset\n",
        "dataset.iloc[0] \n",
        "dataset.iloc[1:10]\n",
        "dataset.iloc[:5]\n",
        "\n",
        "# call the specific value \n",
        "dataset = dataset.set_index(dataset['Birth.Weight'])\n",
        "dataset.loc[120]\n",
        "# 10. rename the columns\n",
        "dataset.rename(columns={'Birth.Weight' : 'Birth of Weight'}).head(3)\n",
        "\n",
        "# 11. find the minimum and maximum , sum , count\n",
        "dataset.min()\n",
        "dataset.max()\n",
        "dataset.sum()\n",
        "dataset.count()\n",
        "\n",
        "# 12. delete the row and column\n",
        "# delete first column\n",
        "dataset.drop('Gestational.Days', axis = 1).head(5)\n",
        "dataset.drop(dataset.columns[1], axis = 1) # delete column at index 1\n",
        "\n",
        "# 13. unique value\n",
        "dataset['Gestational.Days'].unique()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "CuEBNEHkpZ0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1pMrcQnHtwmE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}